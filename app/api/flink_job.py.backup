"""Flinkä½œä¸šç®¡ç†APIæ¥å£"""
import os
import re
import json
import asyncio
import subprocess
from typing import Dict, Any, Optional
from datetime import datetime
from enum import Enum
from pathlib import Path
from fastapi import APIRouter, Depends, HTTPException, status, BackgroundTasks, Query
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel, Field
from loguru import logger

from app.services.database_service import get_db_session

router = APIRouter(prefix="", tags=["Flinkä½œä¸šç®¡ç†"])


def parse_flink_job_info(script_output: str) -> Dict[str, Any]:
    """
    è§£æè„šæœ¬è¾“å‡ºä¸­çš„Flinkä½œä¸šä¿¡æ¯ï¼Œä»JobIDè¾“å‡ºä¸­æå–ä½œä¸šID
    
    Args:
        script_output: è„šæœ¬è¾“å‡ºå†…å®¹
        
    Returns:
        Dict: è§£æåçš„ä½œä¸šä¿¡æ¯
    """
    try:
        # é¦–å…ˆå°è¯•æå– JobID - æ ¼å¼ï¼šJob has been submitted with JobID xxxxxx
        job_id_pattern = r'Job has been submitted with JobID ([a-fA-F0-9]+)'
        job_id_match = re.search(job_id_pattern, script_output)
        
        if job_id_match:
            job_id = job_id_match.group(1)
            logger.info(f"ä»è„šæœ¬è¾“å‡ºä¸­æå–åˆ°JobID: {job_id}")
            
            # è¿”å›åŸºç¡€ä½œä¸šä¿¡æ¯ï¼Œç¨åä¼šé€šè¿‡APIæŸ¥è¯¢è¯¦ç»†ä¿¡æ¯
            return {
                "success": True,
                "job_id": job_id,
                "source": "script_output",
                "timestamp": datetime.now().isoformat()
            }
        
        # å¦‚æœæ²¡æ‰¾åˆ°JobIDï¼Œå°è¯•åŸæ¥çš„JSONæ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
        json_pattern = r'=== FLINK_JOB_INFO_START ===(.*?)=== FLINK_JOB_INFO_END ==='
        json_match = re.search(json_pattern, script_output, re.DOTALL)
        
        if json_match:
            json_str = json_match.group(1).strip()
            # å°è¯•è§£æJSON
            try:
                job_info = json.loads(json_str)
                logger.info(f"æˆåŠŸè§£æJSONæ ¼å¼ä½œä¸šä¿¡æ¯: job_id={job_info.get('job_id', 'unknown')}")
                return job_info
            except json.JSONDecodeError as e:
                logger.error(f"JSONè§£æå¤±è´¥: {e}, åŸå§‹å†…å®¹: {json_str}")
                return {
                    "success": False,
                    "error": "ä½œä¸šä¿¡æ¯JSONæ ¼å¼é”™è¯¯",
                    "raw_content": json_str
                }
        
        # éƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›å¤±è´¥ä¿¡æ¯
        logger.warning("æœªåœ¨è„šæœ¬è¾“å‡ºä¸­æ‰¾åˆ°JobIDæˆ–ä½œä¸šä¿¡æ¯æ ‡è®°")
        return {
            "success": False,
            "error": "æœªæ‰¾åˆ°JobIDæˆ–ä½œä¸šä¿¡æ¯",
            "raw_output": script_output[-500:]  # ä¿ç•™æœ€å500å­—ç¬¦ç”¨äºè°ƒè¯•
        }
        
    except Exception as e:
        logger.error(f"è§£æä½œä¸šä¿¡æ¯å¼‚å¸¸: {e}")
        return {
            "success": False,
            "error": f"è§£æå¼‚å¸¸: {str(e)}"
        }


def fetch_job_details_by_id_sync(job_id: str, environment: str = "multichain-dev") -> Dict[str, Any]:
    """
    æ ¹æ®JobIDé€šè¿‡SSHè¿æ¥åˆ°FlinkæœåŠ¡å™¨æŸ¥è¯¢ä½œä¸šè¯¦ç»†ä¿¡æ¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
    
    Args:
        job_id: Flinkä½œä¸šID
        environment: ç¯å¢ƒæ ‡è¯†
        
    Returns:
        Dict: ä½œä¸šè¯¦ç»†ä¿¡æ¯
    """
    try:
        # FlinkæœåŠ¡å™¨é…ç½®
        flink_server = "35.208.145.201"
        flink_user = "ops"
        
        logger.info(f"åŒæ­¥æŸ¥è¯¢ä½œä¸šè¯¦æƒ…: JobID={job_id}, ç¯å¢ƒ={environment}")
        
        # é€šè¿‡SSHè¿æ¥æŸ¥è¯¢ä½œä¸šä¿¡æ¯
        cmd = [
            "ssh", "-o", "ConnectTimeout=10", f"{flink_user}@{flink_server}",
            f"timeout 15 curl -s http://localhost:8081/jobs/{job_id}"
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        
        if result.returncode == 0:
            job_detail_text = result.stdout.strip()
            
            if job_detail_text:
                try:
                    job_detail = json.loads(job_detail_text)
                    
                    # æå–å…³é”®ä¿¡æ¯
                    job_name = job_detail.get('name', 'Unknown')
                    job_state = job_detail.get('state', 'Unknown')
                    start_time = job_detail.get('start-time', 0)
                    
                    response = {
                        "success": True,
                        "job_id": job_id,
                        "job_name": job_name,
                        "job_state": job_state,
                        "start_time": start_time,
                        "environment": environment,
                        "flink_ui_url": f"http://{flink_server}:8081",
                        "job_detail_url": f"http://{flink_server}:8081/#/job/{job_id}/overview",
                        "timestamp": datetime.now().isoformat(),
                        "raw_detail": job_detail
                    }
                    
                    logger.info(f"åŒæ­¥æˆåŠŸè·å–ä½œä¸šè¯¦æƒ…: JobID={job_id}, çŠ¶æ€={job_state}")
                    return response
                    
                except json.JSONDecodeError as e:
                    logger.error(f"åŒæ­¥è§£æä½œä¸šè¯¦æƒ…JSONå¤±è´¥: {e}")
                    return {
                        "success": False,
                        "job_id": job_id,
                        "error": "ä½œä¸šè¯¦æƒ…JSONè§£æå¤±è´¥",
                        "raw_response": job_detail_text[:500]
                    }
            else:
                logger.warning(f"åŒæ­¥è·å–ä½œä¸šè¯¦æƒ…ä¸ºç©º: JobID={job_id}")
                return {
                    "success": False,
                    "job_id": job_id,
                    "error": "ä½œä¸šè¯¦æƒ…ä¸ºç©º"
                }
        else:
            error_text = result.stderr if result.stderr else "Unknown error"
            logger.error(f"åŒæ­¥æŸ¥è¯¢ä½œä¸šè¯¦æƒ…å¤±è´¥: JobID={job_id}, é”™è¯¯={error_text}")
            return {
                "success": False,
                "job_id": job_id,
                "error": f"æŸ¥è¯¢ä½œä¸šè¯¦æƒ…å¤±è´¥: {error_text}"
            }
            
    except subprocess.TimeoutExpired:
        logger.error(f"åŒæ­¥æŸ¥è¯¢ä½œä¸šè¯¦æƒ…è¶…æ—¶: JobID={job_id}")
        return {
            "success": False,
            "job_id": job_id,
            "error": "æŸ¥è¯¢ä½œä¸šè¯¦æƒ…è¶…æ—¶"
        }
    except Exception as e:
        logger.error(f"åŒæ­¥æŸ¥è¯¢ä½œä¸šè¯¦æƒ…å¼‚å¸¸: JobID={job_id}, å¼‚å¸¸={str(e)}")
        return {
            "success": False,
            "job_id": job_id,
            "error": f"æŸ¥è¯¢å¼‚å¸¸: {str(e)}"
        }


async def fetch_job_details_by_id(job_id: str, environment: str = "multichain-dev") -> Dict[str, Any]:
    """
    æ ¹æ®JobIDé€šè¿‡SSHè¿æ¥åˆ°FlinkæœåŠ¡å™¨æŸ¥è¯¢ä½œä¸šè¯¦ç»†ä¿¡æ¯
    
    Args:
        job_id: Flinkä½œä¸šID
        environment: ç¯å¢ƒæ ‡è¯†
        
    Returns:
        Dict: ä½œä¸šè¯¦ç»†ä¿¡æ¯
    """
    try:
        # FlinkæœåŠ¡å™¨é…ç½®
        flink_server = "35.208.145.201"
        flink_user = "ops"
        
        logger.info(f"æŸ¥è¯¢ä½œä¸šè¯¦æƒ…: JobID={job_id}, ç¯å¢ƒ={environment}")
        
        # é€šè¿‡SSHè¿æ¥æŸ¥è¯¢ä½œä¸šä¿¡æ¯
        cmd = [
            "ssh", "-o", "ConnectTimeout=10", f"{flink_user}@{flink_server}",
            f"timeout 15 curl -s http://localhost:8081/jobs/{job_id}"
        ]
        
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=30)
        
        if process.returncode == 0:
            job_detail_text = stdout.decode('utf-8').strip()
            
            if job_detail_text:
                try:
                    job_detail = json.loads(job_detail_text)
                    
                    # æå–å…³é”®ä¿¡æ¯
                    job_name = job_detail.get('name', 'Unknown')
                    job_state = job_detail.get('state', 'Unknown')
                    start_time = job_detail.get('start-time', 0)
                    
                    result = {
                        "success": True,
                        "job_id": job_id,
                        "job_name": job_name,
                        "job_state": job_state,
                        "start_time": start_time,
                        "environment": environment,
                        "flink_ui_url": f"http://{flink_server}:8081",
                        "job_detail_url": f"http://{flink_server}:8081/#/job/{job_id}/overview",
                        "timestamp": datetime.now().isoformat(),
                        "raw_detail": job_detail
                    }
                    
                    logger.info(f"æˆåŠŸè·å–ä½œä¸šè¯¦æƒ…: JobID={job_id}, çŠ¶æ€={job_state}")
                    return result
                    
                except json.JSONDecodeError as e:
                    logger.error(f"è§£æä½œä¸šè¯¦æƒ…JSONå¤±è´¥: {e}")
                    return {
                        "success": False,
                        "job_id": job_id,
                        "error": "ä½œä¸šè¯¦æƒ…JSONè§£æå¤±è´¥",
                        "raw_response": job_detail_text[:500]
                    }
            else:
                logger.warning(f"è·å–ä½œä¸šè¯¦æƒ…ä¸ºç©º: JobID={job_id}")
                return {
                    "success": False,
                    "job_id": job_id,
                    "error": "ä½œä¸šè¯¦æƒ…ä¸ºç©º"
                }
        else:
            error_text = stderr.decode('utf-8') if stderr else "Unknown error"
            logger.error(f"æŸ¥è¯¢ä½œä¸šè¯¦æƒ…å¤±è´¥: JobID={job_id}, é”™è¯¯={error_text}")
            return {
                "success": False,
                "job_id": job_id,
                "error": f"æŸ¥è¯¢ä½œä¸šè¯¦æƒ…å¤±è´¥: {error_text}"
            }
            
    except asyncio.TimeoutError:
        logger.error(f"æŸ¥è¯¢ä½œä¸šè¯¦æƒ…è¶…æ—¶: JobID={job_id}")
        return {
            "success": False,
            "job_id": job_id,
            "error": "æŸ¥è¯¢ä½œä¸šè¯¦æƒ…è¶…æ—¶"
        }
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ä½œä¸šè¯¦æƒ…å¼‚å¸¸: JobID={job_id}, å¼‚å¸¸={str(e)}")
        return {
            "success": False,
            "job_id": job_id,
            "error": f"æŸ¥è¯¢å¼‚å¸¸: {str(e)}"
        }


class EnvironmentType(str, Enum):
    """ç¯å¢ƒç±»å‹æšä¸¾"""
    MULTICHAIN_DEV = "multichain-dev"
    MULTICHAIN_PROD = "multichain-prod"


class OperationType(str, Enum):
    """æ“ä½œç±»å‹æšä¸¾"""
    DEPLOY = "deploy"
    BUILD = "build"
    UPLOAD = "upload"
    STATUS = "status"


class StartFlinkJobResponse(BaseModel):
    """å¯åŠ¨Flinkä½œä¸šå“åº”æ¨¡å‹"""
    success: bool = Field(..., description="æ“ä½œæ˜¯å¦æˆåŠŸå¯åŠ¨")
    message: str = Field(..., description="æ“ä½œæ¶ˆæ¯")
    data: Dict[str, Any] = Field(default_factory=dict, description="è¿”å›æ•°æ®")


class FlinkJobStatusResponse(BaseModel):
    """Flinkä½œä¸šçŠ¶æ€å“åº”æ¨¡å‹"""
    success: bool = Field(..., description="æŸ¥è¯¢æ˜¯å¦æˆåŠŸ")
    message: str = Field(..., description="çŠ¶æ€æ¶ˆæ¯")
    data: Dict[str, Any] = Field(default_factory=dict, description="çŠ¶æ€æ•°æ®")


async def execute_shell_script(script_path: str, environment: str, operation: str) -> Dict[str, Any]:
    """
    å¼‚æ­¥æ‰§è¡Œshellè„šæœ¬
    
    Args:
        script_path: è„šæœ¬è·¯å¾„
        environment: ç¯å¢ƒå‚æ•°
        operation: æ“ä½œå‚æ•°
    
    Returns:
        æ‰§è¡Œç»“æœå­—å…¸
    """
    try:
        logger.info(f"å¼€å§‹æ‰§è¡ŒFlinkéƒ¨ç½²è„šæœ¬: {script_path} {environment} {operation}")
        
        # æ„å»ºå‘½ä»¤
        cmd = [script_path, environment, operation]
        
        # è®¾ç½®å·¥ä½œç›®å½•ä¸ºè„šæœ¬æ‰€åœ¨ç›®å½•
        script_dir = Path(script_path).parent
        
        # å¼‚æ­¥æ‰§è¡Œå‘½ä»¤
        process = await asyncio.create_subprocess_exec(
            *cmd,
            cwd=script_dir,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        stdout, stderr = await process.communicate()
        
        # è§£ç è¾“å‡º
        stdout_text = stdout.decode('utf-8') if stdout else ""
        stderr_text = stderr.decode('utf-8') if stderr else ""
        
        # è§£æè„šæœ¬è¾“å‡ºä¸­çš„ä½œä¸šä¿¡æ¯
        job_info = None
        if process.returncode == 0:
            basic_job_info = parse_flink_job_info(stdout_text)
            if basic_job_info and basic_job_info.get('success') and basic_job_info.get('job_id'):
                # å¦‚æœæˆåŠŸæå–åˆ°JobIDï¼ŒæŸ¥è¯¢è¯¦ç»†ä¿¡æ¯
                job_id = basic_job_info.get('job_id')
                logger.info(f"æå–åˆ°JobID: {job_id}, å¼€å§‹æŸ¥è¯¢ä½œä¸šè¯¦æƒ…...")
                job_info = await fetch_job_details_by_id(job_id, environment)
            else:
                job_info = basic_job_info
        
        result = {
            "return_code": process.returncode,
            "stdout": stdout_text,
            "stderr": stderr_text,
            "success": process.returncode == 0,
            "command": " ".join(cmd),
            "execution_time": datetime.now().isoformat(),
            "job_info": job_info
        }
        
        if process.returncode == 0:
            logger.info(f"Flinkéƒ¨ç½²è„šæœ¬æ‰§è¡ŒæˆåŠŸ: {environment} {operation}")
            if job_info and job_info.get('success'):
                logger.info(f"è·å–ä½œä¸šä¿¡æ¯æˆåŠŸ: {job_info.get('job_id', 'unknown')}")
        else:
            logger.error(f"Flinkéƒ¨ç½²è„šæœ¬æ‰§è¡Œå¤±è´¥: {environment} {operation}, é”™è¯¯ç : {process.returncode}")
        
        return result
        
    except Exception as e:
        logger.error(f"æ‰§è¡ŒFlinkéƒ¨ç½²è„šæœ¬å¼‚å¸¸: {str(e)}")
        return {
            "return_code": -1,
            "stdout": "",
            "stderr": str(e),
            "success": False,
            "command": " ".join(cmd) if 'cmd' in locals() else "unknown",
            "execution_time": datetime.now().isoformat(),
            "error": str(e)
        }


def execute_shell_script_sync(script_path: str, environment: str, operation: str) -> Dict[str, Any]:
    """
    åŒæ­¥æ‰§è¡Œshellè„šæœ¬
    
    Args:
        script_path: è„šæœ¬è·¯å¾„
        environment: ç¯å¢ƒå‚æ•°
        operation: æ“ä½œå‚æ•°
    
    Returns:
        æ‰§è¡Œç»“æœå­—å…¸
    """
    try:
        logger.info(f"åŒæ­¥æ‰§è¡ŒFlinkéƒ¨ç½²è„šæœ¬: {script_path} {environment} {operation}")
        
        # æ„å»ºå‘½ä»¤
        cmd = [script_path, environment, operation]
        
        # è®¾ç½®å·¥ä½œç›®å½•ä¸ºè„šæœ¬æ‰€åœ¨ç›®å½•
        script_dir = Path(script_path).parent
        
        # åŒæ­¥æ‰§è¡Œå‘½ä»¤
        result = subprocess.run(
            cmd,
            cwd=script_dir,
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        
        # è§£æè„šæœ¬è¾“å‡ºä¸­çš„ä½œä¸šä¿¡æ¯
        job_info = None
        if result.returncode == 0:
            basic_job_info = parse_flink_job_info(result.stdout)
            if basic_job_info and basic_job_info.get('success') and basic_job_info.get('job_id'):
                # å¦‚æœæˆåŠŸæå–åˆ°JobIDï¼ŒæŸ¥è¯¢è¯¦ç»†ä¿¡æ¯
                job_id = basic_job_info.get('job_id')
                logger.info(f"æå–åˆ°JobID: {job_id}, å¼€å§‹æŸ¥è¯¢ä½œä¸šè¯¦æƒ…...")
                job_info = fetch_job_details_by_id_sync(job_id, environment)
            else:
                job_info = basic_job_info
        
        execution_result = {
            "return_code": result.returncode,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "success": result.returncode == 0,
            "command": " ".join(cmd),
            "execution_time": datetime.now().isoformat(),
            "job_info": job_info
        }
        
        if result.returncode == 0:
            logger.info(f"Flinkéƒ¨ç½²è„šæœ¬æ‰§è¡ŒæˆåŠŸ: {environment} {operation}")
            if job_info and job_info.get('success'):
                logger.info(f"è·å–ä½œä¸šä¿¡æ¯æˆåŠŸ: {job_info.get('job_id', 'unknown')}")
        else:
            logger.error(f"Flinkéƒ¨ç½²è„šæœ¬æ‰§è¡Œå¤±è´¥: {environment} {operation}, é”™è¯¯ç : {result.returncode}")
        
        return execution_result
        
    except subprocess.TimeoutExpired:
        logger.error(f"Flinkéƒ¨ç½²è„šæœ¬æ‰§è¡Œè¶…æ—¶: {environment} {operation}")
        return {
            "return_code": -2,
            "stdout": "",
            "stderr": "æ‰§è¡Œè¶…æ—¶",
            "success": False,
            "command": " ".join(cmd),
            "execution_time": datetime.now().isoformat(),
            "error": "æ‰§è¡Œè¶…æ—¶"
        }
    except Exception as e:
        logger.error(f"æ‰§è¡ŒFlinkéƒ¨ç½²è„šæœ¬å¼‚å¸¸: {str(e)}")
        return {
            "return_code": -1,
            "stdout": "",
            "stderr": str(e),
            "success": False,
            "command": " ".join(cmd) if 'cmd' in locals() else "unknown",
            "execution_time": datetime.now().isoformat(),
            "error": str(e)
        }


async def background_flink_job(script_path: str, environment: str, operation: str):
    """åå°æ‰§è¡ŒFlinkä½œä¸š"""
    try:
        result = await execute_shell_script(script_path, environment, operation)
        success = result['success']
        job_info = result.get('job_info')
        
        if success:
            logger.info(f"åå°Flinkä½œä¸šå®Œæˆ: {environment} {operation}, æˆåŠŸ: {success}")
            if job_info and job_info.get('success'):
                logger.info(f"ä½œä¸šä¿¡æ¯: JobID={job_info.get('job_id')}, çŠ¶æ€={job_info.get('job_state')}, åç§°={job_info.get('job_name')}")
            else:
                logger.warning(f"æœªè·å–åˆ°æœ‰æ•ˆçš„ä½œä¸šä¿¡æ¯: {job_info}")
        else:
            logger.error(f"åå°Flinkä½œä¸šæ‰§è¡Œå¤±è´¥: {environment} {operation}")
            
    except Exception as e:
        logger.error(f"åå°Flinkä½œä¸šå¼‚å¸¸: {str(e)}")


@router.post("/start-flink-job", response_model=StartFlinkJobResponse, summary="å¯åŠ¨Flinkä½œä¸š")
async def start_flink_job(
    sync_execution: bool = False,
    background_tasks: BackgroundTasks = None,
    session: AsyncSession = Depends(get_db_session)
):
    """
    å¯åŠ¨Flinkä½œä¸šéƒ¨ç½²
    
    ä½¿ç”¨è„šæœ¬é»˜è®¤é…ç½®ï¼š
    - ç¯å¢ƒ: multichain-dev (å¼€å‘ç¯å¢ƒ)
    - æ“ä½œ: deploy (éƒ¨ç½²æ“ä½œ) 
    
    Args:
        sync_execution: æ˜¯å¦åŒæ­¥æ‰§è¡Œï¼ˆé»˜è®¤falseï¼Œå¼‚æ­¥æ‰§è¡Œï¼‰
        background_tasks: åå°ä»»åŠ¡ç®¡ç†å™¨
        session: æ•°æ®åº“ä¼šè¯
    
    Returns:
        StartFlinkJobResponse: æ‰§è¡Œç»“æœï¼ŒåŒæ­¥æ‰§è¡Œæ—¶åŒ…å«å®Œæ•´çš„ä½œä¸šä¿¡æ¯
    """
    try:
        # ä½¿ç”¨è„šæœ¬é»˜è®¤å€¼
        environment_str = "multichain-dev"  # è„šæœ¬é»˜è®¤ç¯å¢ƒ
        operation_str = "deploy"            # è„šæœ¬é»˜è®¤æ“ä½œ
        
        logger.info(f"å¯åŠ¨Flinkä½œä¸šè¯·æ±‚: ç¯å¢ƒ={environment_str}, æ“ä½œ={operation_str}, åŒæ­¥={sync_execution}")
        
        # æŸ¥æ‰¾éƒ¨ç½²è„šæœ¬
        script_path = None
        possible_paths = [
            "app/deploy-to-flink-cluster.sh",         # æ­£å¼è„šæœ¬ä¼˜å…ˆ
            "./deploy-to-flink-cluster.sh",           # å½“å‰ç›®å½•
            "../deploy-to-flink-cluster.sh",          # ä¸Šçº§ç›®å½•
            "app/test-flink-script.sh"                # æµ‹è¯•è„šæœ¬ä½œä¸ºå¤‡é€‰
        ]
        
        for path in possible_paths:
            if Path(path).exists():
                script_path = str(Path(path).resolve())
                break
        
        if not script_path:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="æœªæ‰¾åˆ°éƒ¨ç½²è„šæœ¬æ–‡ä»¶: deploy-to-flink-cluster.sh"
            )
        
        # æ£€æŸ¥è„šæœ¬æ˜¯å¦å¯æ‰§è¡Œ
        if not os.access(script_path, os.X_OK):
            # å°è¯•æ·»åŠ æ‰§è¡Œæƒé™
            try:
                os.chmod(script_path, 0o755)
                logger.info(f"å·²æ·»åŠ è„šæœ¬æ‰§è¡Œæƒé™: {script_path}")
            except Exception as e:
                raise HTTPException(
                    status_code=status.HTTP_403_FORBIDDEN,
                    detail=f"è„šæœ¬æ— æ‰§è¡Œæƒé™ä¸”æ— æ³•ä¿®æ”¹: {str(e)}"
                )
        
        if sync_execution:
            # åŒæ­¥æ‰§è¡Œï¼Œç«‹å³è¿”å›åŒ…å«ä½œä¸šä¿¡æ¯çš„ç»“æœ
            logger.info(f"åŒæ­¥æ‰§è¡ŒFlinkä½œä¸š: {environment_str} {operation_str}")
            result = execute_shell_script_sync(script_path, environment_str, operation_str)
            
            # å‡†å¤‡å“åº”æ•°æ®
            response_data = {
                "environment": environment_str,
                "operation": operation_str,
                "execution_mode": "sync",
                "script_path": script_path,
                "return_code": result["return_code"],
                "execution_time": result["execution_time"],
                "command": result["command"],
                "flink_ui_url": "http://35.208.145.201:8081"
            }
            
            # å¦‚æœæœ‰ä½œä¸šä¿¡æ¯ï¼Œæ·»åŠ åˆ°å“åº”ä¸­
            job_info = result.get("job_info")
            if job_info and job_info.get('success'):
                response_data.update({
                    "job_id": job_info.get('job_id'),
                    "job_name": job_info.get('job_name'),
                    "job_state": job_info.get('job_state'),
                    "start_time": job_info.get('start_time'),
                    "job_detail_url": job_info.get('job_detail_url'),
                    "job_info": job_info
                })
                
            return StartFlinkJobResponse(
                success=result["success"],
                message="Flinkä½œä¸šæ‰§è¡Œå®Œæˆ" if result["success"] else "Flinkä½œä¸šæ‰§è¡Œå¤±è´¥",
                data=response_data
            )
        else:
            # å¼‚æ­¥æ‰§è¡Œï¼ˆä¸ºäº†é¿å…å‰ç«¯è¯·æ±‚è¶…æ—¶ï¼‰
            if background_tasks:
                background_tasks.add_task(
                    background_flink_job, 
                    script_path, 
                    environment_str, 
                    operation_str
                )
            
            logger.info(f"Flinkä½œä¸šå·²åŠ å…¥åå°æ‰§è¡Œé˜Ÿåˆ—: {environment_str} {operation_str}")
            
            return StartFlinkJobResponse(
                success=True,
                message=f"Flinkä½œä¸šå·²å¯åŠ¨ï¼ˆåå°æ‰§è¡Œï¼‰",
                data={
                    "environment": environment_str,
                    "operation": operation_str,
                    "execution_mode": "async",
                    "script_path": script_path,
                    "start_time": datetime.now().isoformat(),
                    "status": "running",
                    "message": "ä½œä¸šæ­£åœ¨åå°æ‰§è¡Œï¼Œè¯·ç¨åæŸ¥çœ‹æ‰§è¡Œç»“æœ",
                    "flink_ui_url": "http://35.208.145.201:8081"
                }
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¯åŠ¨Flinkä½œä¸šå¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"å¯åŠ¨Flinkä½œä¸šå¤±è´¥: {str(e)}"
        )


@router.get("/flink-job/status", response_model=FlinkJobStatusResponse, summary="æŸ¥çœ‹Flinkä½œä¸šçŠ¶æ€")
async def get_flink_job_status(
    session: AsyncSession = Depends(get_db_session)
):
    """
    æŸ¥çœ‹Flinkä½œä¸šçŠ¶æ€
    
    ä½¿ç”¨è„šæœ¬é»˜è®¤ç¯å¢ƒ multichain-dev
    
    Args:
        session: æ•°æ®åº“ä¼šè¯
    
    Returns:
        FlinkJobStatusResponse: çŠ¶æ€ä¿¡æ¯
    """
    try:
        environment_str = "multichain-dev"  # ä½¿ç”¨è„šæœ¬é»˜è®¤ç¯å¢ƒ
        
        logger.info(f"æŸ¥è¯¢Flinkä½œä¸šçŠ¶æ€: ç¯å¢ƒ={environment_str}")
        
        # æŸ¥æ‰¾éƒ¨ç½²è„šæœ¬
        script_path = None
        possible_paths = [
            "app/deploy-to-flink-cluster.sh",         # æ­£å¼è„šæœ¬ä¼˜å…ˆ
            "./deploy-to-flink-cluster.sh",           # å½“å‰ç›®å½•
            "../deploy-to-flink-cluster.sh",          # ä¸Šçº§ç›®å½•
            "app/test-flink-script.sh"                # æµ‹è¯•è„šæœ¬ä½œä¸ºå¤‡é€‰
        ]
        
        for path in possible_paths:
            if Path(path).exists():
                script_path = str(Path(path).resolve())
                break
        
        if not script_path:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="æœªæ‰¾åˆ°éƒ¨ç½²è„šæœ¬æ–‡ä»¶"
            )
        
        # æ‰§è¡ŒçŠ¶æ€æŸ¥è¯¢
        result = execute_shell_script_sync(script_path, environment_str, "status")
        
        return FlinkJobStatusResponse(
            success=result["success"],
            message="çŠ¶æ€æŸ¥è¯¢å®Œæˆ" if result["success"] else "çŠ¶æ€æŸ¥è¯¢å¤±è´¥",
            data={
                "environment": environment_str,
                "operation": "status",
                "return_code": result["return_code"],
                "stdout": result["stdout"],
                "stderr": result["stderr"],
                "execution_time": result["execution_time"],
                "flink_ui_url": "http://35.208.145.201:8081"
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æŸ¥è¯¢Flinkä½œä¸šçŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æŸ¥è¯¢çŠ¶æ€å¤±è´¥: {str(e)}"
        ) 


class FlinkJobInfoResponse(BaseModel):
    """Flinkä½œä¸šä¿¡æ¯å“åº”æ¨¡å‹"""
    success: bool = Field(..., description="æŸ¥è¯¢æ˜¯å¦æˆåŠŸ")
    message: str = Field(..., description="å“åº”æ¶ˆæ¯")
    data: Dict[str, Any] = Field(default_factory=dict, description="ä½œä¸šä¿¡æ¯æ•°æ®")


def parse_job_details_output(script_output: str, output_format: str) -> Dict[str, Any]:
    """
    è§£æget-flink-job-details.shè„šæœ¬è¾“å‡º
    
    Args:
        script_output: è„šæœ¬è¾“å‡ºå†…å®¹
        output_format: è¾“å‡ºæ ¼å¼ (pretty, json, simple)
        
    Returns:
        Dict: è§£æåçš„ä½œä¸šä¿¡æ¯
    """
    try:
        if not script_output.strip():
            return {
                "success": False,
                "error": "è„šæœ¬è¾“å‡ºä¸ºç©º",
                "jobs": []
            }
        
        jobs = []
        
        if output_format == "json":
            # å°è¯•è§£æJSONæ ¼å¼è¾“å‡ºï¼Œå¤„ç†å¤šè¡ŒJSON
            lines = script_output.strip().split('\n')
            current_json_lines = []
            in_json = False
            brace_count = 0
            
            for line in lines:
                line = line.strip()
                # è·³è¿‡ç©ºè¡Œå’ŒéJSONè¡Œ
                if not line or line.startswith('=') or line.startswith('ğŸ”') or line.startswith('âœ…'):
                    continue
                    
                if line.startswith('{'):
                    in_json = True
                    current_json_lines = [line]
                    brace_count = line.count('{') - line.count('}')
                elif in_json:
                    current_json_lines.append(line)
                    brace_count += line.count('{') - line.count('}')
                    
                    # å½“å¤§æ‹¬å·å¹³è¡¡æ—¶ï¼ŒJSONç»“æŸ
                    if brace_count == 0:
                        json_text = '\n'.join(current_json_lines)
                        try:
                            # æ¸…ç†å¯èƒ½çš„é—®é¢˜å­—ç¬¦å’Œæ¢è¡Œ
                            json_text = json_text.replace('\n', ' ').replace('  ', ' ')
                            # å¤„ç†å¯èƒ½çš„å­—æ®µå€¼é”™è¯¯ï¼ˆå¦‚é‡å¤çš„IDï¼‰
                            json_text = re.sub(r'("[^"]*":\s*")([^"]*\n[^"]*)"', r'\1\2"', json_text)
                            # å¤„ç†ç©ºå€¼
                            json_text = json_text.replace(': ,', ': null,').replace(':,', ': null,')
                            
                            job_data = json.loads(json_text)
                            jobs.append(job_data)
                        except json.JSONDecodeError as e:
                            logger.warning(f"JSONè§£æå¤±è´¥: {e}, åŸå§‹å†…å®¹å‰200å­—ç¬¦: {json_text[:200]}")
                            # å°è¯•æ‰‹åŠ¨è§£æå…³é”®å­—æ®µ
                            manual_job = {}
                            for field in ['job_id', 'job_name', 'job_state', 'start_time']:
                                pattern = f'"{field}":\\s*"([^"]*)"'
                                match = re.search(pattern, json_text)
                                if match:
                                    manual_job[field] = match.group(1)
                            if manual_job.get('job_id'):
                                jobs.append(manual_job)
                        
                        in_json = False
                        current_json_lines = []
                        brace_count = 0
                    
        elif output_format == "simple":
            # è§£æsimpleæ ¼å¼: job_id|job_name|job_state|start_time
            lines = script_output.strip().split('\n')
            for line in lines:
                if '|' in line and not line.startswith('=') and not line.startswith('ğŸ”'):
                    parts = line.split('|')
                    if len(parts) >= 4:
                        jobs.append({
                            "job_id": parts[0].strip(),
                            "job_name": parts[1].strip(),
                            "job_state": parts[2].strip(),
                            "start_time": parts[3].strip()
                        })
        else:
            # è§£æprettyæ ¼å¼ï¼Œæå–å…³é”®ä¿¡æ¯
            lines = script_output.strip().split('\n')
            current_job = {}
            
            for line in lines:
                line = line.strip()
                if line.startswith('ğŸ†” ä½œä¸šID'):
                    current_job = {}
                    current_job["job_id"] = line.split(':', 1)[1].strip()
                elif line.startswith('ğŸ“ ä½œä¸šåç§°') and current_job:
                    current_job["job_name"] = line.split(':', 1)[1].strip()
                elif line.startswith('ğŸ”„ ä½œä¸šçŠ¶æ€') and current_job:
                    current_job["job_state"] = line.split(':', 1)[1].strip()
                elif line.startswith('â° å¯åŠ¨æ—¶é—´') and current_job:
                    current_job["start_time"] = line.split(':', 1)[1].strip()
                elif line.startswith('â±ï¸ è¿è¡Œæ—¶é•¿') and current_job:
                    current_job["duration"] = line.split(':', 1)[1].strip()
                elif line.startswith('ğŸŒ Web UI') and current_job:
                    current_job["web_ui_url"] = line.split(':', 1)[1].strip()
                elif line.startswith('ğŸ”— REST API') and current_job:
                    current_job["rest_api_url"] = line.split(':', 1)[1].strip()
                    # å½“é‡åˆ°REST APIè¡Œæ—¶ï¼Œè¯´æ˜å½“å‰ä½œä¸šä¿¡æ¯æ”¶é›†å®Œæ¯•
                    if current_job.get("job_id"):
                        jobs.append(current_job.copy())
                        current_job = {}
        
        # ä»è¾“å‡ºä¸­æå–è¿è¡Œæ—¶é—´ã€æŸ¥è¯¢æ—¶é—´ç­‰å…ƒä¿¡æ¯
        metadata = {
            "query_time": datetime.now().isoformat(),
            "output_format": output_format,
            "flink_server": "http://35.208.145.201:8081"
        }
        
        # æŸ¥æ‰¾æ˜¯å¦æœ‰æˆåŠŸä¿¡æ¯
        success_match = re.search(r'âœ… æŸ¥è¯¢å®Œæˆï¼Œå…±æ‰¾åˆ° (\d+) ä¸ªè¿è¡Œä¸­çš„åŒ¹é…ä½œä¸š', script_output)
        if success_match:
            metadata["running_jobs_count"] = int(success_match.group(1))
        
        return {
            "success": len(jobs) > 0,
            "jobs": jobs,
            "metadata": metadata,
            "total_jobs": len(jobs)
        }
        
    except Exception as e:
        logger.error(f"è§£æä½œä¸šè¯¦æƒ…è¾“å‡ºå¼‚å¸¸: {e}")
        return {
            "success": False,
            "error": f"è§£æå¼‚å¸¸: {str(e)}",
            "raw_output": script_output[-1000:] if script_output else ""
        }


async def execute_job_details_script(job_name: Optional[str] = None, output_format: str = "json") -> Dict[str, Any]:
    """
    å¼‚æ­¥æ‰§è¡Œget-flink-job-details.shè„šæœ¬
    
    Args:
        job_name: ä½œä¸šåç§°è¿‡æ»¤å™¨ (é»˜è®¤ä¸ºMultiChainTokenJob)
        output_format: è¾“å‡ºæ ¼å¼ (pretty, json, simple)
    
    Returns:
        æ‰§è¡Œç»“æœå­—å…¸
    """
    try:
        # æŸ¥æ‰¾è„šæœ¬æ–‡ä»¶
        script_path = None
        possible_paths = [
            "/Users/qmk/Documents/code/chain-data-parser/app/get-flink-job-details.sh",
            "app/get-flink-job-details.sh",
            "./app/get-flink-job-details.sh",
            "../app/get-flink-job-details.sh",
            "get-flink-job-details.sh"
        ]
        
        for path in possible_paths:
            if Path(path).exists():
                script_path = str(Path(path).resolve())
                break
        
        if not script_path:
            return {
                "success": False,
                "error": "æœªæ‰¾åˆ°get-flink-job-details.shè„šæœ¬æ–‡ä»¶",
                "searched_paths": possible_paths
            }
        
        # æ£€æŸ¥è„šæœ¬æ˜¯å¦å¯æ‰§è¡Œ
        if not os.access(script_path, os.X_OK):
            try:
                os.chmod(script_path, 0o755)
                logger.info(f"å·²æ·»åŠ è„šæœ¬æ‰§è¡Œæƒé™: {script_path}")
            except Exception as e:
                return {
                    "success": False,
                    "error": f"è„šæœ¬æ— æ‰§è¡Œæƒé™ä¸”æ— æ³•ä¿®æ”¹: {str(e)}"
                }
        
        # æ„å»ºå‘½ä»¤å‚æ•°
        cmd = [script_path]
        if job_name:
            cmd.append(job_name)
        if output_format:
            cmd.append(output_format)
        
        logger.info(f"æ‰§è¡ŒFlinkä½œä¸šè¯¦æƒ…æŸ¥è¯¢: {' '.join(cmd)}")
        
        # å¼‚æ­¥æ‰§è¡Œå‘½ä»¤
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        try:
            stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=60)
        except asyncio.TimeoutError:
            process.kill()
            await process.wait()
            return {
                "success": False,
                "error": "è„šæœ¬æ‰§è¡Œè¶…æ—¶",
                "timeout": 60
            }
        
        # è§£ç è¾“å‡º
        stdout_text = stdout.decode('utf-8') if stdout else ""
        stderr_text = stderr.decode('utf-8') if stderr else ""
        
        # è§£æè„šæœ¬è¾“å‡º
        parsed_result = parse_job_details_output(stdout_text, output_format)
        
        result = {
            "success": process.returncode == 0 and parsed_result.get("success", False),
            "return_code": process.returncode,
            "stdout": stdout_text,
            "stderr": stderr_text,
            "command": " ".join(cmd),
            "execution_time": datetime.now().isoformat(),
            "parsed_data": parsed_result
        }
        
        if result["success"]:
            logger.info(f"Flinkä½œä¸šè¯¦æƒ…æŸ¥è¯¢æˆåŠŸ, æ‰¾åˆ° {parsed_result.get('total_jobs', 0)} ä¸ªä½œä¸š")
        else:
            logger.error(f"Flinkä½œä¸šè¯¦æƒ…æŸ¥è¯¢å¤±è´¥: è¿”å›ç ={process.returncode}")
        
        return result
        
    except Exception as e:
        logger.error(f"æ‰§è¡ŒFlinkä½œä¸šè¯¦æƒ…è„šæœ¬å¼‚å¸¸: {str(e)}")
        return {
            "success": False,
            "error": f"æ‰§è¡Œå¼‚å¸¸: {str(e)}",
            "execution_time": datetime.now().isoformat()
        }


@router.get("/get-job-info", response_model=FlinkJobInfoResponse, summary="è·å–Flinkä½œä¸šè¯¦ç»†ä¿¡æ¯")
async def get_flink_job_info(
    job_name: Optional[str] = Query(None, description="ä½œä¸šåç§°è¿‡æ»¤å™¨ï¼Œé»˜è®¤ä¸ºMultiChainTokenJob"),
    output_format: str = Query("json", description="è¾“å‡ºæ ¼å¼: pretty|json|simple", regex="^(pretty|json|simple)$"),
    session: AsyncSession = Depends(get_db_session)
):
    """
    æ‰§è¡Œget-flink-job-details.shè„šæœ¬è·å–Flinkä½œä¸šè¯¦ç»†ä¿¡æ¯
    
    è¯¥æ¥å£ä¼šæ‰§è¡Œget-flink-job-details.shè„šæœ¬æ¥æŸ¥è¯¢è¿è¡Œä¸­çš„Flinkä½œä¸šä¿¡æ¯ã€‚
    åªè¿”å›çŠ¶æ€ä¸ºRUNNINGçš„ä½œä¸šã€‚
    
    Args:
        job_name: ä½œä¸šåç§°è¿‡æ»¤å™¨ (å¯é€‰ï¼Œé»˜è®¤ä¸ºMultiChainTokenJob)
        output_format: è¾“å‡ºæ ¼å¼ (pretty|json|simple, é»˜è®¤json)
        session: æ•°æ®åº“ä¼šè¯
    
    Returns:
        FlinkJobInfoResponse: åŒ…å«ä½œä¸šè¯¦ç»†ä¿¡æ¯çš„å“åº”
    """
    try:
        logger.info(f"è·å–Flinkä½œä¸šä¿¡æ¯è¯·æ±‚: job_name={job_name}, format={output_format}")
        
        # æ‰§è¡Œè„šæœ¬
        result = await execute_job_details_script(job_name, output_format)
        
        if result["success"]:
            parsed_data = result["parsed_data"]
            jobs = parsed_data.get("jobs", [])
            metadata = parsed_data.get("metadata", {})
            
            response_data = {
                "jobs": jobs,
                "total_jobs": len(jobs),
                "metadata": metadata,
                "execution_info": {
                    "command": result["command"],
                    "execution_time": result["execution_time"],
                    "return_code": result["return_code"]
                }
            }
            
            return FlinkJobInfoResponse(
                success=True,
                message=f"æˆåŠŸè·å–åˆ° {len(jobs)} ä¸ªè¿è¡Œä¸­çš„ä½œä¸šä¿¡æ¯",
                data=response_data
            )
        else:
            # æ‰§è¡Œå¤±è´¥ï¼Œä½†ä»è¿”å›éƒ¨åˆ†ä¿¡æ¯ç”¨äºè°ƒè¯•
            error_data = {
                "error": result.get("error", "æœªçŸ¥é”™è¯¯"),
                "return_code": result.get("return_code", -1),
                "stderr": result.get("stderr", ""),
                "stdout": result.get("stdout", "")[:500],  # é™åˆ¶è¾“å‡ºé•¿åº¦
                "command": result.get("command", ""),
                "execution_time": result.get("execution_time", "")
            }
            
            return FlinkJobInfoResponse(
                success=False,
                message=f"è·å–ä½œä¸šä¿¡æ¯å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                data=error_data
            )
            
    except Exception as e:
        logger.error(f"è·å–Flinkä½œä¸šä¿¡æ¯å¼‚å¸¸: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"è·å–ä½œä¸šä¿¡æ¯å¼‚å¸¸: {str(e)}"
        ) 