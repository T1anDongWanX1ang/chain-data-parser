#!/usr/bin/env python3
"""
æµ‹è¯•ä¼˜åŒ–ç‰ˆç®¡é“æ‰§è¡Œå™¨çš„æ—¥å¿—è·¯å¾„ç»‘å®šåŠŸèƒ½
"""

import asyncio
import json
import sys
import tempfile
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from app.component.pipeline_executor_optimized import OptimizedBlockchainDataPipeline, PipelineContext


async def test_log_path_binding():
    """æµ‹è¯•æ—¥å¿—è·¯å¾„ç»‘å®šåŠŸèƒ½"""
    
    print("ğŸ§ª æµ‹è¯•ä¼˜åŒ–ç‰ˆç®¡é“æ‰§è¡Œå™¨çš„æ—¥å¿—è·¯å¾„ç»‘å®šåŠŸèƒ½")
    print("=" * 60)
    
    # åˆ›å»ºä¸´æ—¶æ—¥å¿—æ–‡ä»¶è·¯å¾„
    temp_dir = Path(tempfile.mkdtemp())
    log_file_path = temp_dir / "pipeline_test.log"
    
    print(f"ğŸ“ ä¸´æ—¶æ—¥å¿—ç›®å½•: {temp_dir}")
    print(f"ğŸ“„ æ—¥å¿—æ–‡ä»¶è·¯å¾„: {log_file_path}")
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    test_config = {
        "pipeline_name": "æ—¥å¿—è·¯å¾„ç»‘å®šæµ‹è¯•ç®¡é“",
        "description": "æµ‹è¯•æ—¥å¿—è¾“å‡ºåˆ°æŒ‡å®šè·¯å¾„",
        "classification_id": 1,
        "components": [
            {
                "name": "test_event_monitor",
                "type": "event_monitor",
                "chain_name": "ethereum",
                "contract_address": "0xA0b86a33E6441c8C06DD2b7c94b7E0e8d61c6e8e",
                "abi_path": "abis/erc20.json",
                "mode": "realtime",
                "events_to_monitor": ["Transfer"],
                "output_format": "detailed",
                "poll_interval": 1.0
            },
            {
                "name": "test_dict_mapper",
                "type": "dict_mapper",
                "dict_mappers": [
                    {
                        "event_name": "Transfer",
                        "mapping_rules": [
                            {
                                "source_key": "from",
                                "target_key": "sender_address",
                                "transformer": "to_lowercase",
                                "condition": None,
                                "default_value": None
                            },
                            {
                                "source_key": "to",
                                "target_key": "receiver_address",
                                "transformer": "to_lowercase",
                                "condition": None,
                                "default_value": None
                            },
                            {
                                "source_key": "value",
                                "target_key": "amount",
                                "transformer": None,
                                "condition": None,
                                "default_value": "0"
                            }
                        ]
                    }
                ]
            },
            {
                "name": "test_kafka_producer",
                "type": "kafka_producer",
                "bootstrap_servers": "localhost:9092",
                "topic": "test_topic",
                "acks": 1,
                "sync_send": False
            }
        ]
    }
    
    try:
        print("\nğŸ”„ åˆ›å»ºå¸¦æ—¥å¿—è·¯å¾„çš„ç®¡é“å®ä¾‹...")
        
        # åˆ›å»ºç®¡é“å®ä¾‹ï¼ŒæŒ‡å®šæ—¥å¿—è·¯å¾„
        pipeline = OptimizedBlockchainDataPipeline(
            config_dict=test_config,
            log_path=str(log_file_path)
        )
        
        print(f"âœ… ç®¡é“å®ä¾‹åˆ›å»ºæˆåŠŸï¼Œå®ä¾‹ID: {pipeline.instance_id}")
        
        # åˆå§‹åŒ–ç»„ä»¶
        print("\nğŸ”„ åˆå§‹åŒ–ç®¡é“ç»„ä»¶...")
        await pipeline._initialize_components()
        print(f"âœ… ç»„ä»¶åˆå§‹åŒ–å®Œæˆï¼Œå…± {len(pipeline.components)} ä¸ªç»„ä»¶")
        
        # æ¨¡æ‹Ÿå¤„ç†ä¸€äº›æ•°æ®
        print("\nğŸ”„ æ¨¡æ‹Ÿæ•°æ®å¤„ç†...")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = {
            "event_name": "Transfer",
            "from": "0x1234567890ABCDEF1234567890ABCDEF12345678",
            "to": "0xABCDEF1234567890ABCDEF1234567890ABCDEF12",
            "value": "1000000000000000000",  # 1 ETH in wei
            "block_number": 18500000,
            "transaction_hash": "0xtest123456789",
            "log_index": 0
        }
        
        # åˆ›å»ºç®¡é“ä¸Šä¸‹æ–‡
        context = PipelineContext(data=test_data)
        
        # å¤„ç†æ•°æ®ï¼ˆè·³è¿‡ç¬¬ä¸€ä¸ªç»„ä»¶ï¼Œä»ç¬¬äºŒä¸ªå¼€å§‹ï¼‰
        processed_context = await pipeline._process_pipeline_data(context)
        
        print(f"âœ… æ•°æ®å¤„ç†å®Œæˆ")
        print(f"ğŸ“Š å¤„ç†ç»“æœå­—æ®µæ•°: {len(processed_context.data)}")
        
        # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶æ˜¯å¦åˆ›å»º
        print(f"\nğŸ” æ£€æŸ¥æ—¥å¿—æ–‡ä»¶...")
        if log_file_path.exists():
            file_size = log_file_path.stat().st_size
            print(f"âœ… æ—¥å¿—æ–‡ä»¶å·²åˆ›å»º: {log_file_path}")
            print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
            
            # è¯»å–å¹¶æ˜¾ç¤ºæ—¥å¿—å†…å®¹çš„å‰å‡ è¡Œ
            print(f"\nğŸ“„ æ—¥å¿—æ–‡ä»¶å†…å®¹é¢„è§ˆ:")
            print("-" * 50)
            with open(log_file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                for i, line in enumerate(lines[:10]):  # æ˜¾ç¤ºå‰10è¡Œ
                    print(f"{i+1:2d}: {line.rstrip()}")
                
                if len(lines) > 10:
                    print(f"... (è¿˜æœ‰ {len(lines) - 10} è¡Œ)")
            print("-" * 50)
        else:
            print("âŒ æ—¥å¿—æ–‡ä»¶æœªåˆ›å»º")
            return False
        
        # æµ‹è¯•å¤šä¸ªå®ä¾‹çš„æ—¥å¿—éš”ç¦»
        print(f"\nğŸ”„ æµ‹è¯•å¤šå®ä¾‹æ—¥å¿—éš”ç¦»...")
        
        # åˆ›å»ºç¬¬äºŒä¸ªç®¡é“å®ä¾‹ï¼Œä½¿ç”¨ç›¸åŒçš„æ—¥å¿—æ–‡ä»¶
        pipeline2 = OptimizedBlockchainDataPipeline(
            config_dict=test_config,
            log_path=str(log_file_path)
        )
        
        print(f"âœ… ç¬¬äºŒä¸ªç®¡é“å®ä¾‹åˆ›å»ºæˆåŠŸï¼Œå®ä¾‹ID: {pipeline2.instance_id}")
        
        # æ£€æŸ¥ä¸¤ä¸ªå®ä¾‹çš„IDæ˜¯å¦ä¸åŒ
        if pipeline.instance_id != pipeline2.instance_id:
            print(f"âœ… å®ä¾‹IDéš”ç¦»æ­£å¸¸: {pipeline.instance_id} != {pipeline2.instance_id}")
        else:
            print(f"âš ï¸  å®ä¾‹IDç›¸åŒï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜")
        
        # æ¸…ç†èµ„æº
        print(f"\nğŸ§¹ æ¸…ç†æµ‹è¯•èµ„æº...")
        pipeline._cleanup_logging()
        pipeline2._cleanup_logging()
        
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        if log_file_path.exists():
            log_file_path.unlink()
        temp_dir.rmdir()
        
        print(f"âœ… æ¸…ç†å®Œæˆ")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_relative_log_path():
    """æµ‹è¯•ç›¸å¯¹è·¯å¾„æ—¥å¿—é…ç½®"""
    
    print(f"\nğŸ§ª æµ‹è¯•ç›¸å¯¹è·¯å¾„æ—¥å¿—é…ç½®")
    print("-" * 40)
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•é…ç½®
    simple_config = {
        "pipeline_name": "ç›¸å¯¹è·¯å¾„æ—¥å¿—æµ‹è¯•",
        "description": "æµ‹è¯•ç›¸å¯¹è·¯å¾„æ—¥å¿—è¾“å‡º",
        "classification_id": 1,
        "components": [
            {
                "name": "simple_event_monitor",
                "type": "event_monitor",
                "chain_name": "ethereum",
                "contract_address": "0xA0b86a33E6441c8C06DD2b7c94b7E0e8d61c6e8e",
                "abi_path": "abis/erc20.json",
                "mode": "realtime",
                "events_to_monitor": ["Transfer"],
                "output_format": "detailed"
            }
        ]
    }
    
    try:
        # ä½¿ç”¨ç›¸å¯¹è·¯å¾„
        relative_log_path = "logs/test_relative_path.log"
        
        print(f"ğŸ“ ç›¸å¯¹æ—¥å¿—è·¯å¾„: {relative_log_path}")
        
        # åˆ›å»ºç®¡é“å®ä¾‹
        pipeline = OptimizedBlockchainDataPipeline(
            config_dict=simple_config,
            log_path=relative_log_path
        )
        
        print(f"âœ… ç›¸å¯¹è·¯å¾„ç®¡é“åˆ›å»ºæˆåŠŸï¼Œå®ä¾‹ID: {pipeline.instance_id}")
        
        # æ£€æŸ¥å®é™…çš„æ—¥å¿—æ–‡ä»¶è·¯å¾„
        project_root = Path(__file__).parent
        expected_log_file = project_root / relative_log_path
        
        print(f"ğŸ“„ é¢„æœŸæ—¥å¿—æ–‡ä»¶è·¯å¾„: {expected_log_file}")
        
        # æ¸…ç†
        pipeline._cleanup_logging()
        
        # å¦‚æœæ—¥å¿—æ–‡ä»¶å­˜åœ¨ï¼Œåˆ é™¤å®ƒ
        if expected_log_file.exists():
            expected_log_file.unlink()
            print(f"ğŸ§¹ æ¸…ç†æ—¥å¿—æ–‡ä»¶: {expected_log_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç›¸å¯¹è·¯å¾„æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_no_log_path():
    """æµ‹è¯•ä¸æŒ‡å®šæ—¥å¿—è·¯å¾„çš„æƒ…å†µ"""
    
    print(f"\nğŸ§ª æµ‹è¯•ä¸æŒ‡å®šæ—¥å¿—è·¯å¾„ï¼ˆä»…æ§åˆ¶å°è¾“å‡ºï¼‰")
    print("-" * 45)
    
    simple_config = {
        "pipeline_name": "ä»…æ§åˆ¶å°æ—¥å¿—æµ‹è¯•",
        "description": "æµ‹è¯•ä»…æ§åˆ¶å°æ—¥å¿—è¾“å‡º",
        "classification_id": 1,
        "components": [
            {
                "name": "console_only_monitor",
                "type": "event_monitor",
                "chain_name": "ethereum",
                "contract_address": "0xA0b86a33E6441c8C06DD2b7c94b7E0e8d61c6e8e",
                "abi_path": "abis/erc20.json",
                "mode": "realtime",
                "events_to_monitor": ["Transfer"],
                "output_format": "detailed"
            }
        ]
    }
    
    try:
        # ä¸æŒ‡å®šæ—¥å¿—è·¯å¾„
        pipeline = OptimizedBlockchainDataPipeline(config_dict=simple_config)
        
        print(f"âœ… ä»…æ§åˆ¶å°æ—¥å¿—ç®¡é“åˆ›å»ºæˆåŠŸï¼Œå®ä¾‹ID: {pipeline.instance_id}")
        print(f"ğŸ“‹ æ—¥å¿—å¤„ç†å™¨æ•°é‡: {len(pipeline.logger_ids)}")
        
        # æ¸…ç†
        pipeline._cleanup_logging()
        
        return True
        
    except Exception as e:
        print(f"âŒ ä»…æ§åˆ¶å°æ—¥å¿—æµ‹è¯•å¤±è´¥: {e}")
        return False


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æµ‹è¯•ä¼˜åŒ–ç‰ˆç®¡é“æ‰§è¡Œå™¨çš„æ—¥å¿—è·¯å¾„ç»‘å®šåŠŸèƒ½")
    print("=" * 70)
    
    # æµ‹è¯•ç»å¯¹è·¯å¾„æ—¥å¿—ç»‘å®š
    success1 = await test_log_path_binding()
    
    # æµ‹è¯•ç›¸å¯¹è·¯å¾„æ—¥å¿—é…ç½®
    success2 = await test_relative_log_path()
    
    # æµ‹è¯•ä¸æŒ‡å®šæ—¥å¿—è·¯å¾„
    success3 = await test_no_log_path()
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print("=" * 30)
    
    if success1:
        print("âœ… ç»å¯¹è·¯å¾„æ—¥å¿—ç»‘å®šæµ‹è¯•é€šè¿‡")
    else:
        print("âŒ ç»å¯¹è·¯å¾„æ—¥å¿—ç»‘å®šæµ‹è¯•å¤±è´¥")
    
    if success2:
        print("âœ… ç›¸å¯¹è·¯å¾„æ—¥å¿—é…ç½®æµ‹è¯•é€šè¿‡")
    else:
        print("âŒ ç›¸å¯¹è·¯å¾„æ—¥å¿—é…ç½®æµ‹è¯•å¤±è´¥")
    
    if success3:
        print("âœ… ä»…æ§åˆ¶å°æ—¥å¿—æµ‹è¯•é€šè¿‡")
    else:
        print("âŒ ä»…æ§åˆ¶å°æ—¥å¿—æµ‹è¯•å¤±è´¥")
    
    if success1 and success2 and success3:
        print(f"\nğŸ‰ æ‰€æœ‰æ—¥å¿—è·¯å¾„ç»‘å®šæµ‹è¯•é€šè¿‡ï¼")
        print("ğŸ“‹ éªŒè¯åŠŸèƒ½:")
        print("   âœ… æ”¯æŒç»å¯¹è·¯å¾„æ—¥å¿—æ–‡ä»¶è¾“å‡º")
        print("   âœ… æ”¯æŒç›¸å¯¹è·¯å¾„æ—¥å¿—æ–‡ä»¶è¾“å‡º")
        print("   âœ… æ”¯æŒä»…æ§åˆ¶å°æ—¥å¿—è¾“å‡º")
        print("   âœ… å¤šå®ä¾‹æ—¥å¿—éš”ç¦»æ­£å¸¸")
        print("   âœ… æ—¥å¿—æ–‡ä»¶è‡ªåŠ¨åˆ›å»ºç›®å½•")
        print("   âœ… æ—¥å¿—è½®è½¬å’Œå‹ç¼©é…ç½®")
        print("   âœ… å®ä¾‹IDæ ‡è¯†å’Œè¿‡æ»¤")
    else:
        print(f"\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")


if __name__ == "__main__":
    asyncio.run(main())
